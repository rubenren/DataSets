{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting alpha_vantage\n",
      "  Downloading alpha_vantage-2.3.1-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\jr101\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from alpha_vantage) (2.24.0)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.1-cp37-cp37m-win_amd64.whl (551 kB)\n",
      "     -------------------------------------- 551.8/551.8 KB 8.7 MB/s eta 0:00:00\n",
      "Collecting charset-normalizer<3.0,>=2.0\n",
      "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp37-cp37m-win_amd64.whl (121 kB)\n",
      "     ---------------------------------------- 121.3/121.3 KB ? eta 0:00:00\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jr101\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from aiohttp->alpha_vantage) (19.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\jr101\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from aiohttp->alpha_vantage) (3.7.4.3)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting asynctest==0.13.0\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp37-cp37m-win_amd64.whl (27 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.0-cp37-cp37m-win_amd64.whl (33 kB)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\jr101\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->alpha_vantage) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\jr101\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->alpha_vantage) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jr101\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->alpha_vantage) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\jr101\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests->alpha_vantage) (2.10)\n",
      "Installing collected packages: multidict, frozenlist, charset-normalizer, asynctest, async-timeout, yarl, aiosignal, aiohttp, alpha_vantage\n",
      "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 alpha_vantage-2.3.1 async-timeout-4.0.2 asynctest-0.13.0 charset-normalizer-2.0.12 frozenlist-1.3.0 multidict-6.0.2 yarl-1.7.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\jr101\\AppData\\Local\\Programs\\Python\\Python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install alpha_vantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from alpha_vantage.timeseries import TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load my api key\n",
    "load_dotenv()\n",
    "MY_KEY = os.getenv('ALPHA_VANTAGE_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = TimeSeries(key=MY_KEY, output_format='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ticker</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "      <th>release_date</th>\n",
       "      <th>provider</th>\n",
       "      <th>url</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221515</td>\n",
       "      <td>NIO</td>\n",
       "      <td>Why Shares of Chinese Electric Car Maker NIO A...</td>\n",
       "      <td>news</td>\n",
       "      <td>What s happening\\nShares of Chinese electric c...</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>The Motley Fool</td>\n",
       "      <td>https://invst.ly/pigqi</td>\n",
       "      <td>2060327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221516</td>\n",
       "      <td>NIO</td>\n",
       "      <td>NIO only consumer gainer  Workhorse Group amon...</td>\n",
       "      <td>news</td>\n",
       "      <td>Gainers  NIO  NYSE NIO   7  \\nLosers  MGP Ingr...</td>\n",
       "      <td>2020-01-18</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>https://invst.ly/pje9c</td>\n",
       "      <td>2062196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221517</td>\n",
       "      <td>NIO</td>\n",
       "      <td>NIO leads consumer gainers  Beyond Meat and Ma...</td>\n",
       "      <td>news</td>\n",
       "      <td>Gainers  NIO  NYSE NIO   14   Village Farms In...</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>https://invst.ly/pifmv</td>\n",
       "      <td>2060249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221518</td>\n",
       "      <td>NIO</td>\n",
       "      <td>NIO  NVAX among premarket gainers</td>\n",
       "      <td>news</td>\n",
       "      <td>Cemtrex  NASDAQ CETX   85  after FY results \\n...</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>https://invst.ly/picu8</td>\n",
       "      <td>2060039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221519</td>\n",
       "      <td>NIO</td>\n",
       "      <td>PLUG  NIO among premarket gainers</td>\n",
       "      <td>news</td>\n",
       "      <td>aTyr Pharma  NASDAQ LIFE   63  on Kyorin Pharm...</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>https://seekingalpha.com/news/3529772-plug-nio...</td>\n",
       "      <td>2053096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id ticker                                              title category  \\\n",
       "0  221515    NIO  Why Shares of Chinese Electric Car Maker NIO A...     news   \n",
       "1  221516    NIO  NIO only consumer gainer  Workhorse Group amon...     news   \n",
       "2  221517    NIO  NIO leads consumer gainers  Beyond Meat and Ma...     news   \n",
       "3  221518    NIO                  NIO  NVAX among premarket gainers     news   \n",
       "4  221519    NIO                  PLUG  NIO among premarket gainers     news   \n",
       "\n",
       "                                             content release_date  \\\n",
       "0  What s happening\\nShares of Chinese electric c...   2020-01-15   \n",
       "1  Gainers  NIO  NYSE NIO   7  \\nLosers  MGP Ingr...   2020-01-18   \n",
       "2  Gainers  NIO  NYSE NIO   14   Village Farms In...   2020-01-15   \n",
       "3  Cemtrex  NASDAQ CETX   85  after FY results \\n...   2020-01-15   \n",
       "4  aTyr Pharma  NASDAQ LIFE   63  on Kyorin Pharm...   2020-01-06   \n",
       "\n",
       "          provider                                                url  \\\n",
       "0  The Motley Fool                             https://invst.ly/pigqi   \n",
       "1    Seeking Alpha                             https://invst.ly/pje9c   \n",
       "2    Seeking Alpha                             https://invst.ly/pifmv   \n",
       "3    Seeking Alpha                             https://invst.ly/picu8   \n",
       "4    Seeking Alpha  https://seekingalpha.com/news/3529772-plug-nio...   \n",
       "\n",
       "   article_id  \n",
       "0     2060327  \n",
       "1     2062196  \n",
       "2     2060249  \n",
       "3     2060039  \n",
       "4     2053096  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/archive.zip')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting ready to get the historical data for the most talked about tickers\n",
    "most_popular = df.ticker.value_counts()\n",
    "most_popular = most_popular.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AAPL     20231\n",
       "MSFT      8110\n",
       "BAC       7409\n",
       "AMZN      6330\n",
       "NWSA      5914\n",
       "BA        5879\n",
       "GOOGL     5171\n",
       "GS        4513\n",
       "TSLA      4283\n",
       "NFLX      3806\n",
       "TGT       3689\n",
       "INTC      3188\n",
       "DIS       2875\n",
       "XOM       2831\n",
       "JPM       2600\n",
       "MS        2498\n",
       "GM        2089\n",
       "C         2082\n",
       "GE        2045\n",
       "MU        1927\n",
       "TM        1822\n",
       "WMB       1482\n",
       "KO        1367\n",
       "WFC       1359\n",
       "WMT       1267\n",
       "Name: ticker, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing out TimeSeries and how it works\n",
    "data, meta_data = ts.get_daily('AAPL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1. Information': 'Daily Prices (open, high, low, close) and Volumes',\n",
       " '2. Symbol': 'AAPL',\n",
       " '3. Last Refreshed': '2022-05-16',\n",
       " '4. Output Size': 'Compact',\n",
       " '5. Time Zone': 'US/Eastern'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-05-16'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(data.index[0]).split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to create a function to download and save the stock data\n",
    "def download_stock(symbol):\n",
    "    data, _ = ts.get_daily(symbol=symbol, outputsize='full')\n",
    "    filename = symbol + '_' + str(data.index[-1]).split()[0] + '_' + str(data.index[0]).split()[0] + '.csv'\n",
    "    filepath = 'data/' + filename\n",
    "    data.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download for: AAPL\n",
      "Finished download for: AAPL\n",
      "waiting for 20 seconds before next iteration...\n",
      "Starting download for: MSFT\n",
      "Finished download for: MSFT\n",
      "waiting for 20 seconds before next iteration...\n",
      "Starting download for: BAC\n",
      "Finished download for: BAC\n",
      "waiting for 20 seconds before next iteration...\n",
      "Starting download for: AMZN\n",
      "Finished download for: AMZN\n",
      "waiting for 20 seconds before next iteration...\n",
      "Starting download for: NWSA\n",
      "Finished download for: NWSA\n",
      "waiting for 20 seconds before next iteration...\n",
      "Starting download for: BA\n",
      "Finished download for: BA\n",
      "waiting for 20 seconds before next iteration...\n",
      "Starting download for: GOOGL\n",
      "Finished download for: GOOGL\n",
      "waiting for 20 seconds before next iteration...\n",
      "Starting download for: GS\n",
      "Finished download for: GS\n",
      "waiting for 20 seconds before next iteration...\n",
      "Starting download for: TSLA\n",
      "Finished download for: TSLA\n",
      "waiting for 20 seconds before next iteration...\n",
      "Starting download for: NFLX\n",
      "Finished download for: NFLX\n",
      "waiting for 20 seconds before next iteration...\n",
      "Starting download for: TGT\n",
      "Finished download for: TGT\n",
      "waiting for 20 seconds before next iteration...\n",
      "Starting download for: INTC\n",
      "Finished download for: INTC\n",
      "waiting for 20 seconds before next iteration...\n",
      "Starting download for: DIS\n",
      "Finished download for: DIS\n",
      "waiting for 20 seconds before next iteration...\n",
      "Starting download for: XOM\n",
      "Finished download for: XOM\n",
      "waiting for 20 seconds before next iteration...\n",
      "Starting download for: JPM\n",
      "Finished download for: JPM\n",
      "waiting for 20 seconds before next iteration...\n",
      "Starting download for: MS\n",
      "Finished download for: MS\n",
      "waiting for 20 seconds before next iteration...\n",
      "Starting download for: GM\n",
      "Finished download for: GM\n",
      "waiting for 20 seconds before next iteration...\n",
      "Starting download for: C\n",
      "Finished download for: C\n",
      "waiting for 20 seconds before next iteration...\n",
      "Starting download for: GE\n",
      "Finished download for: GE\n",
      "waiting for 20 seconds before next iteration...\n",
      "Starting download for: MU\n",
      "Finished download for: MU\n",
      "waiting for 20 seconds before next iteration...\n",
      "Starting download for: TM\n",
      "Finished download for: TM\n",
      "waiting for 20 seconds before next iteration...\n",
      "Starting download for: WMB\n",
      "Finished download for: WMB\n",
      "waiting for 20 seconds before next iteration...\n",
      "Starting download for: KO\n",
      "Finished download for: KO\n",
      "waiting for 20 seconds before next iteration...\n",
      "Starting download for: WFC\n",
      "Finished download for: WFC\n",
      "waiting for 20 seconds before next iteration...\n",
      "Starting download for: WMT\n",
      "Finished download for: WMT\n",
      "waiting for 20 seconds before next iteration...\n",
      "Done downloading all the files!\n"
     ]
    }
   ],
   "source": [
    "# Finally to set up a loop that should wait long enough before querying for the next stock\n",
    "for symbol in most_popular.keys():\n",
    "    print(\"Starting download for:\", symbol)\n",
    "    download_stock(symbol)\n",
    "    print(\"Finished download for:\", symbol)\n",
    "    print(\"waiting for 20 seconds before next iteration...\")\n",
    "    time.sleep(20)\n",
    "    \n",
    "print(\"Done downloading all the files!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_stock('SPY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to save the news data for the different stocks\n",
    "to_save = df[df.ticker.isin(most_popular.keys())]\n",
    "to_save.to_csv('data/top25-headlines.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

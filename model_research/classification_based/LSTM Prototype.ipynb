{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d532cab",
   "metadata": {},
   "source": [
    "I want to try out multiclass, and see if I get better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f86d76e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix, roc_auc_score\n",
    "from tensorflow.keras import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "025ed79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for one of our technical indicators\n",
    "def calc_rsi(df, periods = 14, ema = True):\n",
    "    \"\"\"\n",
    "    Returns a pd.Series with the relative strength index.\n",
    "    \"\"\"\n",
    "    close_delta = df.adj_close.diff()\n",
    "\n",
    "    # Make two series: one for lower closes and one for higher closes\n",
    "    up = close_delta.clip(lower=0)\n",
    "    down = -1 * close_delta.clip(upper=0)\n",
    "    \n",
    "    if ema == True:\n",
    "        # Use exponential moving average\n",
    "        ma_up = up.ewm(com = periods - 1, adjust=True, min_periods = periods).mean()\n",
    "        ma_down = down.ewm(com = periods - 1, adjust=True, min_periods = periods).mean()\n",
    "    else:\n",
    "        # Use simple moving average\n",
    "        ma_up = up.rolling(window = periods, adjust=False).mean()\n",
    "        ma_down = down.rolling(window = periods, adjust=False).mean()\n",
    "        \n",
    "    rsi = ma_up / ma_down\n",
    "    rsi = 100 - (100/(1 + rsi))\n",
    "    return rsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ebe342f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining our preprocessing\n",
    "def read_data(filename):\n",
    "    # read in the data\n",
    "    data = pd.read_csv(filename)\n",
    "    data = data.rename(str.lower, axis=1)\n",
    "    data = data.rename(mapper={'adj close': 'adj_close'}, axis=1)\n",
    "    data.date = pd.to_datetime(data.date)\n",
    "    data = data.set_index('date')\n",
    "    return data\n",
    "\n",
    "def add_features(df):\n",
    "    # accumulation/Distribution line\n",
    "    mult = ((df.close - df.low) - (df.high - df.close)) / (df.high - df.low)\n",
    "    MFVolume = mult * df.volume\n",
    "    accum_dist_indicator = MFVolume.cumsum()\n",
    "    ret_df = pd.concat([df, accum_dist_indicator], axis=1)\n",
    "    ret_df = ret_df.rename(mapper={0:'accum_dist_indicator'}, axis=1)\n",
    "    \n",
    "    #MACD\n",
    "    EMA_12 = df.adj_close.ewm(span=12, adjust=False).mean()\n",
    "    EMA_26 = df.adj_close.ewm(span=26, adjust=False).mean()\n",
    "    macd = EMA_12 - EMA_26\n",
    "    signal = macd.ewm(span=9, adjust=False).mean()\n",
    "    ret_df = pd.concat([ret_df, macd.rename('macd'), signal.rename('signal_macd')], axis=1)\n",
    "    \n",
    "    #RSI\n",
    "    rsi = calc_rsi(df)\n",
    "    ret_df = pd.concat([ret_df, rsi.rename('rsi')], axis=1)\n",
    "    \n",
    "    return ret_df\n",
    "\n",
    "def series_to_supervised(data, n_in=1, n_out=1, col_names = [], indicies = [], preds = [], dropnan=True):\n",
    "    '''\n",
    "    Convert a time series to a supervised learning dataset\n",
    "    Args:\n",
    "        data -> time series to convert as a list or numpy array\n",
    "        n_in -> number of lag observations as input (X)\n",
    "        n_out -> number of observations as output (y)\n",
    "        col_names -> names of the columns\n",
    "        indicies -> list of the indicies\n",
    "        preds -> list of column indicies to determine which variables to predict\n",
    "        dropnan -> flag of whether to drop the rows with NaN\n",
    "    Returns:\n",
    "        Pandas DataFrame of series framed for supervised learning\n",
    "    '''\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('%s(t-%d)' % (col_names[j], i)) for j in range(n_vars)]\n",
    "    # forecast sequence\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df[col_names[preds]].shift(-i))\n",
    "        if i==0:\n",
    "            names += [('%s(t)' % (col_names[j])) for j in preds]\n",
    "        else:\n",
    "            names += [('%s(t+%d)' % (col_names[j], i)) for j in preds]\n",
    "    # putting it together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    agg.index = indicies\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "def scale(in_train, in_test, with_labels=False):\n",
    "    '''\n",
    "    Rescales the train and test sets\n",
    "    Args:\n",
    "        train -> numpy array of the training data\n",
    "        test -> numpy array of the test data\n",
    "        with_labels -> if set to true will cut off last column before scaling,\n",
    "            reattached after scaling\n",
    "    Returns:\n",
    "        scaler -> the scaler object for transforming\n",
    "        train_scaled -> a rescaled version of the train data\n",
    "        test_scaled -> a rescaled version of the test data\n",
    "    '''\n",
    "    train = in_train\n",
    "    test = in_test\n",
    "    if with_labels:\n",
    "        train_labels = train[:,-1]\n",
    "        train = train[:,:-1]\n",
    "        test_labels = test[:,-1]\n",
    "        test = test[:,:-1]\n",
    "    # scale train and test to [-1,1]\n",
    "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    scaler = scaler.fit(train)\n",
    "    # transform train\n",
    "    train = train.reshape(train.shape[0], train.shape[1])\n",
    "    train_scaled = scaler.transform(train)\n",
    "    # transform test\n",
    "    test = test.reshape(test.shape[0], test.shape[1])\n",
    "    test_scaled = scaler.transform(test)\n",
    "    if with_labels:\n",
    "        train_scaled.append(train_labels, axis=1)\n",
    "        test_scaled.append(test_labels, axis=1)\n",
    "    return scaler, train_scaled, test_scaled\n",
    "\n",
    "def split_data(data, test_percent):\n",
    "    '''\n",
    "    Splits the data by percentage amount\n",
    "    Returns: train, test\n",
    "    '''\n",
    "    split_val = int(len(data) * (1 - test_percent))\n",
    "    train, test = data[:split_val], data[split_val:]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9937be50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_separation(x):\n",
    "    if x < -.05:\n",
    "        return -2\n",
    "    elif x < -.005:\n",
    "        return -1\n",
    "    elif x > .05:\n",
    "        return 2\n",
    "    elif x > .005:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def prep_data(filename, lookback=14):\n",
    "    temp = np.array([0,1,2,-1,-2]).reshape(-1,1)\n",
    "    # read in the data\n",
    "    data = read_data(filename)\n",
    "    # add technical indicators as features\n",
    "    data = add_features(data)\n",
    "    # frame as an RNN problem\n",
    "    data = series_to_supervised(data, lookback, 5, data.columns, data.index, [4])\n",
    "    # only keep the predictive columns I care about\n",
    "    data = data.drop(data.columns[-5:-1], axis=1)\n",
    "    labels = (data['adj_close(t+4)'] - data['adj_close(t-1)']) / data['adj_close(t-1)']\n",
    "    labels = labels.apply(class_separation)\n",
    "    data = data.drop(data.columns[-1], axis=1)\n",
    "    data = pd.concat([data, labels.rename('labels')], axis=1)\n",
    "    data_values = data.values\n",
    "    train, test = split_data(data_values, .2)\n",
    "    scaler, train_scaled, test_scaled = scale(train[:,:-1], test[:,:-1])\n",
    "    ohe = OneHotEncoder(sparse=False).fit(temp)\n",
    "    train_scaled = np.append(train_scaled, ohe.transform(train[:,-1].reshape((-1,1))), axis=1)\n",
    "    test_scaled = np.append(test_scaled, ohe.transform(test[:,-1].reshape((-1,1))), axis=1)\n",
    "    return scaler, train_scaled, test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92b3ce71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lstm(train, batch_size, nb_epoch, neurons, label_size=5):\n",
    "    X, y = train[:,:-label_size], train[:,-label_size:]\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    # prepare a model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True, return_sequences=True))\n",
    "    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', 'AUC'])\n",
    "    for i in range(nb_epoch):\n",
    "        if not i % 10:\n",
    "            print('%d/%d' % (i+1, nb_epoch), end='')\n",
    "        else:\n",
    "            print('.', end='')\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=1, shuffle=False)\n",
    "        model.reset_states()\n",
    "    print()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd34aa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "scaler, train, test = prep_data('../../data/SPY_1993-01-29_2022-08-17.csv')\n",
    "# set parameters\n",
    "batches = 16\n",
    "neurons = 32\n",
    "nb_epochs = 250\n",
    "#trim the data and give it to the model\n",
    "train_trimmed = train[len(train)%batches:]\n",
    "test_trimmed = test[:-(len(test) % batches)] if len(test) % batches != 0 else test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9e4cb09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 8s 6ms/step - loss: 1.2322 - accuracy: 0.4367 - auc: 0.7828\n",
      "370/370 [==============================] - 6s 6ms/step - loss: 1.2088 - accuracy: 0.4377 - auc: 0.7888\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.1976 - accuracy: 0.4397 - auc: 0.7917\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.1913 - accuracy: 0.4341 - auc: 0.7928\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.1808 - accuracy: 0.4350 - auc: 0.7956\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.1718 - accuracy: 0.4390 - auc: 0.7985\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.1693 - accuracy: 0.4444 - auc: 0.7995\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.1657 - accuracy: 0.4426 - auc: 0.8010\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.1628 - accuracy: 0.4505 - auc: 0.8020\n",
      "370/370 [==============================] - 3s 6ms/step - loss: 1.1581 - accuracy: 0.4500 - auc: 0.8034\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.1550 - accuracy: 0.4510 - auc: 0.8045\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.1501 - accuracy: 0.4559 - auc: 0.8062\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.1460 - accuracy: 0.4566 - auc: 0.8081\n",
      "370/370 [==============================] - 3s 6ms/step - loss: 1.1407 - accuracy: 0.4639 - auc: 0.8098\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.1366 - accuracy: 0.4622 - auc: 0.8111\n",
      "370/370 [==============================] - 3s 6ms/step - loss: 1.1336 - accuracy: 0.4610 - auc: 0.8125\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.1333 - accuracy: 0.4622 - auc: 0.8124\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.1314 - accuracy: 0.4650 - auc: 0.8132\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.1304 - accuracy: 0.4688 - auc: 0.8129\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.1192 - accuracy: 0.4747 - auc: 0.8170\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.1141 - accuracy: 0.4779 - auc: 0.8192\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.1106 - accuracy: 0.4774 - auc: 0.8200\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.1067 - accuracy: 0.4841 - auc: 0.8220\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.1019 - accuracy: 0.4880 - auc: 0.8242\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.0958 - accuracy: 0.4851 - auc: 0.8263\n",
      "370/370 [==============================] - 3s 6ms/step - loss: 1.0980 - accuracy: 0.4801 - auc: 0.8252\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.0905 - accuracy: 0.4892 - auc: 0.8288\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.0798 - accuracy: 0.4946 - auc: 0.8322\n",
      "370/370 [==============================] - 3s 6ms/step - loss: 1.0788 - accuracy: 0.4985 - auc: 0.8331\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.0726 - accuracy: 0.4949 - auc: 0.8339\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.0654 - accuracy: 0.5039 - auc: 0.8373\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.0734 - accuracy: 0.4924 - auc: 0.8341\n",
      "370/370 [==============================] - 3s 6ms/step - loss: 1.0620 - accuracy: 0.5088 - auc: 0.8387\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 1.0466 - accuracy: 0.5130 - auc: 0.8439\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.0516 - accuracy: 0.5218 - auc: 0.8428\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 1.0455 - accuracy: 0.5198 - auc: 0.8445\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.0405 - accuracy: 0.5264 - auc: 0.8460\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.0239 - accuracy: 0.5279 - auc: 0.8513\n",
      "370/370 [==============================] - 3s 6ms/step - loss: 1.0187 - accuracy: 0.5299 - auc: 0.8525\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.0173 - accuracy: 0.5395 - auc: 0.8537\n",
      "370/370 [==============================] - 3s 6ms/step - loss: 1.0138 - accuracy: 0.5265 - auc: 0.8544\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.0103 - accuracy: 0.5291 - auc: 0.8548\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 1.0081 - accuracy: 0.5319 - auc: 0.8562\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.9916 - accuracy: 0.5395 - auc: 0.8613\n",
      "370/370 [==============================] - 3s 6ms/step - loss: 0.9888 - accuracy: 0.5475 - auc: 0.8616\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.9800 - accuracy: 0.5497 - auc: 0.8657\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.9814 - accuracy: 0.5551 - auc: 0.8641\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.9725 - accuracy: 0.5557 - auc: 0.8673\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.9627 - accuracy: 0.5557 - auc: 0.8701\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.9543 - accuracy: 0.5600 - auc: 0.8715\n",
      "370/370 [==============================] - 3s 6ms/step - loss: 0.9482 - accuracy: 0.5720 - auc: 0.8748\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.9496 - accuracy: 0.5657 - auc: 0.8731\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.9371 - accuracy: 0.5747 - auc: 0.8774\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.9317 - accuracy: 0.5762 - auc: 0.8789\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.9260 - accuracy: 0.5819 - auc: 0.8804\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.9398 - accuracy: 0.5640 - auc: 0.8753\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.9545 - accuracy: 0.5691 - auc: 0.8731\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.9226 - accuracy: 0.5774 - auc: 0.8804\n",
      "370/370 [==============================] - 3s 6ms/step - loss: 0.9164 - accuracy: 0.5792 - auc: 0.8825\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.9129 - accuracy: 0.5814 - auc: 0.8839\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.9083 - accuracy: 0.5873 - auc: 0.8840\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.8973 - accuracy: 0.5917 - auc: 0.8876\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.8879 - accuracy: 0.5917 - auc: 0.8902\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.9025 - accuracy: 0.5853 - auc: 0.8861\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.8877 - accuracy: 0.6002 - auc: 0.8898\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.8694 - accuracy: 0.6090 - auc: 0.8951\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.8717 - accuracy: 0.6042 - auc: 0.8936\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.8616 - accuracy: 0.6172 - auc: 0.8973\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.8689 - accuracy: 0.6093 - auc: 0.8950\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.8691 - accuracy: 0.6073 - auc: 0.8945\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.8676 - accuracy: 0.5990 - auc: 0.8943\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.8478 - accuracy: 0.6166 - auc: 0.9002\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.8494 - accuracy: 0.6144 - auc: 0.9004\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.9220 - accuracy: 0.5833 - auc: 0.8822\n",
      "370/370 [==============================] - 3s 6ms/step - loss: 0.8767 - accuracy: 0.6034 - auc: 0.8924\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.8765 - accuracy: 0.6066 - auc: 0.8938\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.8298 - accuracy: 0.6262 - auc: 0.9052\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.8349 - accuracy: 0.6213 - auc: 0.9036\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.8157 - accuracy: 0.6387 - auc: 0.9084\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.8202 - accuracy: 0.6289 - auc: 0.9071\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.8097 - accuracy: 0.6328 - auc: 0.9093\n",
      "370/370 [==============================] - 3s 6ms/step - loss: 0.8046 - accuracy: 0.6336 - auc: 0.9106\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.7899 - accuracy: 0.6481 - auc: 0.9148\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.8023 - accuracy: 0.6443 - auc: 0.9114\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.8069 - accuracy: 0.6367 - auc: 0.9097\n",
      "370/370 [==============================] - 3s 6ms/step - loss: 0.8103 - accuracy: 0.6400 - auc: 0.9089\n",
      "370/370 [==============================] - 3s 6ms/step - loss: 0.7967 - accuracy: 0.6372 - auc: 0.9122\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.8167 - accuracy: 0.6280 - auc: 0.9073\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.7912 - accuracy: 0.6417 - auc: 0.9134\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.7853 - accuracy: 0.6443 - auc: 0.9148\n",
      "370/370 [==============================] - 3s 6ms/step - loss: 0.7829 - accuracy: 0.6471 - auc: 0.9154\n",
      "370/370 [==============================] - 3s 6ms/step - loss: 0.7663 - accuracy: 0.6527 - auc: 0.9197\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.7803 - accuracy: 0.6495 - auc: 0.9157\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.8106 - accuracy: 0.6340 - auc: 0.9090\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.8752 - accuracy: 0.6034 - auc: 0.8944\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.8110 - accuracy: 0.6316 - auc: 0.9083\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.7986 - accuracy: 0.6476 - auc: 0.9128\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.7801 - accuracy: 0.6522 - auc: 0.9164\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.7646 - accuracy: 0.6568 - auc: 0.9203\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.7500 - accuracy: 0.6684 - auc: 0.9235\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.7602 - accuracy: 0.6639 - auc: 0.9209\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.7668 - accuracy: 0.6529 - auc: 0.9186\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.7487 - accuracy: 0.6698 - auc: 0.9234\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.7361 - accuracy: 0.6743 - auc: 0.9259\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.7515 - accuracy: 0.6655 - auc: 0.9225\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.7547 - accuracy: 0.6590 - auc: 0.9219\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.7409 - accuracy: 0.6760 - auc: 0.9248\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.7330 - accuracy: 0.6709 - auc: 0.9262\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.7424 - accuracy: 0.6725 - auc: 0.9248\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.7643 - accuracy: 0.6578 - auc: 0.9196\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.7430 - accuracy: 0.6696 - auc: 0.9245\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.7262 - accuracy: 0.6787 - auc: 0.9280\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.7181 - accuracy: 0.6868 - auc: 0.9302\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.7156 - accuracy: 0.6855 - auc: 0.9305\n",
      "370/370 [==============================] - 3s 6ms/step - loss: 0.6894 - accuracy: 0.6966 - auc: 0.9358\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.7228 - accuracy: 0.6782 - auc: 0.9283\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.7191 - accuracy: 0.6809 - auc: 0.9293\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.6849 - accuracy: 0.6963 - auc: 0.9368\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.6881 - accuracy: 0.7039 - auc: 0.9361\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.6695 - accuracy: 0.7057 - auc: 0.9398\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.6907 - accuracy: 0.6943 - auc: 0.9351\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.6767 - accuracy: 0.7056 - auc: 0.9384\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.6716 - accuracy: 0.7051 - auc: 0.9388\n",
      "370/370 [==============================] - 3s 6ms/step - loss: 0.6694 - accuracy: 0.7056 - auc: 0.9393\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.6847 - accuracy: 0.7017 - auc: 0.9362\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.6692 - accuracy: 0.7083 - auc: 0.9394\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.6740 - accuracy: 0.7032 - auc: 0.9383\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.6885 - accuracy: 0.6990 - auc: 0.9353\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.6694 - accuracy: 0.7084 - auc: 0.9393\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.6629 - accuracy: 0.7088 - auc: 0.9405\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.6830 - accuracy: 0.7010 - auc: 0.9365\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.6837 - accuracy: 0.6985 - auc: 0.9362\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.6520 - accuracy: 0.7160 - auc: 0.9428\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.6387 - accuracy: 0.7209 - auc: 0.9454\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.6331 - accuracy: 0.7240 - auc: 0.9463\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.6477 - accuracy: 0.7172 - auc: 0.9432\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.6529 - accuracy: 0.7123 - auc: 0.9420\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.6357 - accuracy: 0.7218 - auc: 0.9453\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.6449 - accuracy: 0.7164 - auc: 0.9435\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.6281 - accuracy: 0.7221 - auc: 0.9466\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.6295 - accuracy: 0.7275 - auc: 0.9465\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.6316 - accuracy: 0.7218 - auc: 0.9462\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.6405 - accuracy: 0.7177 - auc: 0.9443\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.6336 - accuracy: 0.7211 - auc: 0.9458\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.6243 - accuracy: 0.7255 - auc: 0.9475\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.6501 - accuracy: 0.7123 - auc: 0.9425\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.6352 - accuracy: 0.7284 - auc: 0.9458\n",
      "370/370 [==============================] - 4s 8ms/step - loss: 0.6087 - accuracy: 0.7448 - auc: 0.9507\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.6237 - accuracy: 0.7309 - auc: 0.9475\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.6134 - accuracy: 0.7250 - auc: 0.9491\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.6068 - accuracy: 0.7307 - auc: 0.9502\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.6016 - accuracy: 0.7407 - auc: 0.9513\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5974 - accuracy: 0.7421 - auc: 0.9521\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.6214 - accuracy: 0.7301 - auc: 0.9475\n",
      "370/370 [==============================] - 3s 6ms/step - loss: 0.6417 - accuracy: 0.7220 - auc: 0.9443\n",
      "370/370 [==============================] - 3s 6ms/step - loss: 0.5975 - accuracy: 0.7426 - auc: 0.9520\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5784 - accuracy: 0.7549 - auc: 0.9555\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5836 - accuracy: 0.7476 - auc: 0.9544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5765 - accuracy: 0.7429 - auc: 0.9554\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5679 - accuracy: 0.7551 - auc: 0.9571\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5759 - accuracy: 0.7478 - auc: 0.9556\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.6036 - accuracy: 0.7336 - auc: 0.9504\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.6000 - accuracy: 0.7326 - auc: 0.9512\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5944 - accuracy: 0.7434 - auc: 0.9524\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5978 - accuracy: 0.7429 - auc: 0.9517\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5724 - accuracy: 0.7495 - auc: 0.9558\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.5694 - accuracy: 0.7532 - auc: 0.9566\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.6098 - accuracy: 0.7319 - auc: 0.9492\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.6179 - accuracy: 0.7236 - auc: 0.9479\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5844 - accuracy: 0.7466 - auc: 0.9538\n",
      "370/370 [==============================] - 3s 6ms/step - loss: 0.5713 - accuracy: 0.7508 - auc: 0.9565\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5784 - accuracy: 0.7507 - auc: 0.9549\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5596 - accuracy: 0.7554 - auc: 0.9580\n",
      "370/370 [==============================] - 3s 6ms/step - loss: 0.5771 - accuracy: 0.7530 - auc: 0.9553\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5811 - accuracy: 0.7485 - auc: 0.9545\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5644 - accuracy: 0.7554 - auc: 0.9570\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5873 - accuracy: 0.7468 - auc: 0.9532\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.5646 - accuracy: 0.7554 - auc: 0.9573\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5779 - accuracy: 0.7498 - auc: 0.9551\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.5357 - accuracy: 0.7720 - auc: 0.9615\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.5801 - accuracy: 0.7481 - auc: 0.9546\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5681 - accuracy: 0.7532 - auc: 0.9564\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5617 - accuracy: 0.7551 - auc: 0.9575\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5522 - accuracy: 0.7628 - auc: 0.9590\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5474 - accuracy: 0.7642 - auc: 0.9597\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5477 - accuracy: 0.7667 - auc: 0.9597\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5610 - accuracy: 0.7650 - auc: 0.9579\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5378 - accuracy: 0.7650 - auc: 0.9612\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5246 - accuracy: 0.7706 - auc: 0.9632\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5231 - accuracy: 0.7774 - auc: 0.9634\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5710 - accuracy: 0.7546 - auc: 0.9559\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5323 - accuracy: 0.7758 - auc: 0.9621\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5365 - accuracy: 0.7735 - auc: 0.9612\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5214 - accuracy: 0.7720 - auc: 0.9633\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5219 - accuracy: 0.7743 - auc: 0.9634\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5313 - accuracy: 0.7740 - auc: 0.9623\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5152 - accuracy: 0.7752 - auc: 0.9644\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5196 - accuracy: 0.7735 - auc: 0.9637\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5433 - accuracy: 0.7606 - auc: 0.9598\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.5431 - accuracy: 0.7642 - auc: 0.9600\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5476 - accuracy: 0.7635 - auc: 0.9595\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5286 - accuracy: 0.7689 - auc: 0.9621\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5544 - accuracy: 0.7569 - auc: 0.9581\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5306 - accuracy: 0.7728 - auc: 0.9618\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5114 - accuracy: 0.7812 - auc: 0.9651\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.4900 - accuracy: 0.7953 - auc: 0.9684\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.4866 - accuracy: 0.7934 - auc: 0.9687\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5497 - accuracy: 0.7650 - auc: 0.9592\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5359 - accuracy: 0.7723 - auc: 0.9612\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5360 - accuracy: 0.7701 - auc: 0.9610\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.5152 - accuracy: 0.7769 - auc: 0.9641\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.4991 - accuracy: 0.7885 - auc: 0.9668\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.4761 - accuracy: 0.8027 - auc: 0.9702\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.5085 - accuracy: 0.7848 - auc: 0.9653\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.4781 - accuracy: 0.7971 - auc: 0.9697\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.5377 - accuracy: 0.7649 - auc: 0.9606\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.4983 - accuracy: 0.7875 - auc: 0.9666\n",
      "370/370 [==============================] - 3s 6ms/step - loss: 0.4873 - accuracy: 0.7917 - auc: 0.9681\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.4828 - accuracy: 0.8020 - auc: 0.9688\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.4701 - accuracy: 0.8025 - auc: 0.9706\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.4923 - accuracy: 0.7909 - auc: 0.9674\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.4888 - accuracy: 0.7917 - auc: 0.9680\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.5080 - accuracy: 0.7848 - auc: 0.9650\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.4887 - accuracy: 0.7919 - auc: 0.9678\n",
      "370/370 [==============================] - 4s 6ms/step - loss: 0.4649 - accuracy: 0.8005 - auc: 0.9713\n",
      "370/370 [==============================] - 4s 8ms/step - loss: 0.4612 - accuracy: 0.8037 - auc: 0.9721\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.4551 - accuracy: 0.8118 - auc: 0.9726\n",
      "370/370 [==============================] - 4s 8ms/step - loss: 0.4839 - accuracy: 0.7910 - auc: 0.9683\n",
      "370/370 [==============================] - 4s 8ms/step - loss: 0.4847 - accuracy: 0.7985 - auc: 0.9684\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.5054 - accuracy: 0.7772 - auc: 0.9651\n",
      "370/370 [==============================] - 4s 8ms/step - loss: 0.5242 - accuracy: 0.7748 - auc: 0.9626\n",
      "370/370 [==============================] - 4s 8ms/step - loss: 0.4980 - accuracy: 0.7861 - auc: 0.9663\n",
      "370/370 [==============================] - 5s 8ms/step - loss: 0.4882 - accuracy: 0.7944 - auc: 0.9680\n",
      "370/370 [==============================] - 4s 8ms/step - loss: 0.4841 - accuracy: 0.7959 - auc: 0.9685\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.4692 - accuracy: 0.8037 - auc: 0.9704\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.4438 - accuracy: 0.8142 - auc: 0.9740\n",
      "370/370 [==============================] - 4s 8ms/step - loss: 0.4633 - accuracy: 0.8035 - auc: 0.9713\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.4397 - accuracy: 0.8150 - auc: 0.9746\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.4575 - accuracy: 0.8034 - auc: 0.9718\n",
      "370/370 [==============================] - 4s 8ms/step - loss: 0.4635 - accuracy: 0.8019 - auc: 0.9709\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.4824 - accuracy: 0.7939 - auc: 0.9685\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.4800 - accuracy: 0.7951 - auc: 0.9689\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.4321 - accuracy: 0.8198 - auc: 0.9755\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.4136 - accuracy: 0.8324 - auc: 0.9779\n",
      "370/370 [==============================] - 4s 8ms/step - loss: 0.4322 - accuracy: 0.8166 - auc: 0.9753\n",
      "370/370 [==============================] - 4s 8ms/step - loss: 0.4270 - accuracy: 0.8228 - auc: 0.9760\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.4705 - accuracy: 0.8041 - auc: 0.9704\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.4912 - accuracy: 0.7929 - auc: 0.9673\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.4741 - accuracy: 0.8042 - auc: 0.9698\n",
      "370/370 [==============================] - 4s 7ms/step - loss: 0.5092 - accuracy: 0.7853 - auc: 0.9650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_model = fit_lstm(train_trimmed, batches, nb_epochs, neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2b0e48d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 5s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.2077448e-06, 2.2671573e-02, 9.3674004e-01, 4.0555473e-02,\n",
       "        3.1706568e-05],\n",
       "       [2.2110155e-06, 3.8984701e-02, 9.1802424e-01, 4.2956367e-02,\n",
       "        3.2455700e-05],\n",
       "       [1.4705214e-06, 6.8180434e-02, 8.4498042e-01, 8.6601466e-02,\n",
       "        2.3623864e-04],\n",
       "       [4.0483943e-07, 3.2408819e-02, 8.8286209e-01, 8.4544219e-02,\n",
       "        1.8435836e-04],\n",
       "       [5.5589896e-07, 3.2389209e-02, 7.5076908e-01, 2.1659625e-01,\n",
       "        2.4494572e-04]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = train_trimmed[:,:-5], train_trimmed[:,-5:]\n",
    "X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "y_pred = lstm_model.predict(X, batch_size=16)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "32ed26f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/370 [==============================] - 6s 5ms/step - loss: 0.7436 - accuracy: 0.7073 - auc: 0.9347\n"
     ]
    }
   ],
   "source": [
    "lstm_model.reset_states()\n",
    "metrics = lstm_model.evaluate(X, y, batch_size=batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c4fd6e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'accuracy', 'auc']\n",
      "[0.7435736656188965, 0.7072635293006897, 0.9346805214881897]\n"
     ]
    }
   ],
   "source": [
    "print(lstm_model.metrics_names)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4417d725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 2s 3ms/step\n",
      "92/92 [==============================] - 2s 6ms/step - loss: 3.0207 - accuracy: 0.2833 - auc: 0.6445\n"
     ]
    }
   ],
   "source": [
    "lstm_model.reset_states()\n",
    "lstm_model.predict(X, batch_size=16)\n",
    "X, y = test_trimmed[:,:-5], test_trimmed[:,-5:]\n",
    "X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "metrics, something, sss = lstm_model.evaluate(X,y, batch_size=batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b7bd445f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'accuracy', 'auc']\n",
      "[3.1463370323181152, 0.2805706560611725, 0.6415072083473206]\n"
     ]
    }
   ],
   "source": [
    "print(lstm_model.metrics_names)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94320791",
   "metadata": {},
   "source": [
    "Overfit pretty well, now time to experiment with different dropout rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7190f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lstm(train, batch_size, nb_epoch, neurons, dropout=.2, label_size=5):\n",
    "    X, y = train[:,:-label_size], train[:,-label_size:]\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    # prepare a model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True, return_sequences=True, dropout=dropout))\n",
    "    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True, dropout=dropout))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.Precision(),\n",
    "                                                                              tf.keras.metrics.Recall(),\n",
    "                                                                              'AUC'])\n",
    "    for i in range(nb_epoch):\n",
    "        if not i % 10:\n",
    "            print('%d/%d' % (i+1, nb_epoch), end='')\n",
    "        else:\n",
    "            print('.', end='')\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "        model.reset_states()\n",
    "    print()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6cacd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(repeats, train, test, dropout_rate):\n",
    "    # paprameters\n",
    "    batch_size = 64\n",
    "    neurons = 32\n",
    "    nb_epochs = 250\n",
    "    prec_scores, recall_scores, auc_scores, losses = list(), list(), list(), list()\n",
    "    for r in range(repeats):\n",
    "        # fit the model\n",
    "        train_trimmed = train[len(train)%batch_size:]\n",
    "        lstm_model = fit_lstm(train_trimmed, batch_size, nb_epochs, neurons, dropout=dropout_rate)\n",
    "        # forecast the training set to set state\n",
    "        train_reshaped = train_trimmed[:,:-5].reshape(len(train_trimmed), 1, -1)\n",
    "        lstm_model.predict(train_reshaped, batch_size=batch_size, verbose=0)\n",
    "        # now forecast the test set\n",
    "        test_trimmed = test[:-(len(test) % batch_size)] if (len(test)%batch_size) != 0 else test\n",
    "        test_reshaped = test_trimmed[:,:-5].reshape(len(test_trimmed), 1, -1)\n",
    "        loss, prec, rec, auc = lstm_model.evaluate(test_reshaped, test_trimmed[:,-5:], batch_size)\n",
    "        print('%d) Test metrics - loss: %.3f, prec: %.3f, rec: %.3f, roc_auc: %.3f' %(r+1, loss, prec, rec, auc))\n",
    "        prec_scores.append(prec)\n",
    "        recall_scores.append(rec)\n",
    "        auc_scores.append(auc)\n",
    "        losses.append(loss)\n",
    "    return losses, prec_scores, recall_scores, auc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9440169d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 2.1500 - precision_4: 0.2656 - recall_4: 0.2262 - auc: 0.6768\n",
      "1) Test metrics - loss: 2.150, prec: 0.266, rec: 0.226, roc_auc: 0.677\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 2.6178 - precision_5: 0.2400 - recall_5: 0.2154 - auc: 0.6338\n",
      "2) Test metrics - loss: 2.618, prec: 0.240, rec: 0.215, roc_auc: 0.634\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 2.8920 - precision_6: 0.2713 - recall_6: 0.2446 - auc: 0.6432\n",
      "3) Test metrics - loss: 2.892, prec: 0.271, rec: 0.245, roc_auc: 0.643\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.5794 - precision_7: 0.3783 - recall_7: 0.2133 - auc: 0.7340\n",
      "4) Test metrics - loss: 1.579, prec: 0.378, rec: 0.213, roc_auc: 0.734\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 2.0712 - precision_8: 0.2821 - recall_8: 0.2317 - auc: 0.6820\n",
      "5) Test metrics - loss: 2.071, prec: 0.282, rec: 0.232, roc_auc: 0.682\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 2.1266 - precision_9: 0.2700 - recall_9: 0.2249 - auc: 0.6616\n",
      "6) Test metrics - loss: 2.127, prec: 0.270, rec: 0.225, roc_auc: 0.662\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 2.4400 - precision_10: 0.2669 - recall_10: 0.2255 - auc: 0.6208\n",
      "7) Test metrics - loss: 2.440, prec: 0.267, rec: 0.226, roc_auc: 0.621\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 2.1223 - precision_11: 0.2640 - recall_11: 0.2147 - auc: 0.6836\n",
      "8) Test metrics - loss: 2.122, prec: 0.264, rec: 0.215, roc_auc: 0.684\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 2.5137 - precision_12: 0.2640 - recall_12: 0.2242 - auc: 0.6418\n",
      "9) Test metrics - loss: 2.514, prec: 0.264, rec: 0.224, roc_auc: 0.642\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.9053 - precision_13: 0.2956 - recall_13: 0.2167 - auc: 0.6908\n",
      "10) Test metrics - loss: 1.905, prec: 0.296, rec: 0.217, roc_auc: 0.691\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.6670 - precision_14: 0.3025 - recall_14: 0.2045 - auc: 0.7166\n",
      "11) Test metrics - loss: 1.667, prec: 0.303, rec: 0.204, roc_auc: 0.717\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 3.0365 - precision_15: 0.2385 - recall_15: 0.2249 - auc: 0.6310\n",
      "12) Test metrics - loss: 3.037, prec: 0.238, rec: 0.225, roc_auc: 0.631\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 2.1708 - precision_16: 0.2144 - recall_16: 0.1257 - auc: 0.6042\n",
      "13) Test metrics - loss: 2.171, prec: 0.214, rec: 0.126, roc_auc: 0.604\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 2.3291 - precision_17: 0.2504 - recall_17: 0.2052 - auc: 0.6282\n",
      "14) Test metrics - loss: 2.329, prec: 0.250, rec: 0.205, roc_auc: 0.628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 5ms/step - loss: 2.3217 - precision_18: 0.2716 - recall_18: 0.2242 - auc: 0.6657\n",
      "15) Test metrics - loss: 2.322, prec: 0.272, rec: 0.224, roc_auc: 0.666\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 5ms/step - loss: 1.6369 - precision_19: 0.3081 - recall_19: 0.1963 - auc: 0.7113\n",
      "1) Test metrics - loss: 1.637, prec: 0.308, rec: 0.196, roc_auc: 0.711\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.9011 - precision_20: 0.2766 - recall_20: 0.2120 - auc: 0.6799\n",
      "2) Test metrics - loss: 1.901, prec: 0.277, rec: 0.212, roc_auc: 0.680\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 5ms/step - loss: 1.6211 - precision_21: 0.3004 - recall_21: 0.2045 - auc: 0.7125\n",
      "3) Test metrics - loss: 1.621, prec: 0.300, rec: 0.204, roc_auc: 0.712\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 5ms/step - loss: 1.5769 - precision_22: 0.2995 - recall_22: 0.1664 - auc: 0.7105\n",
      "4) Test metrics - loss: 1.577, prec: 0.300, rec: 0.166, roc_auc: 0.711\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.8765 - precision_23: 0.2908 - recall_23: 0.2154 - auc: 0.6884\n",
      "5) Test metrics - loss: 1.877, prec: 0.291, rec: 0.215, roc_auc: 0.688\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 2.0914 - precision_24: 0.2326 - recall_24: 0.1957 - auc: 0.6751\n",
      "6) Test metrics - loss: 2.091, prec: 0.233, rec: 0.196, roc_auc: 0.675\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 5ms/step - loss: 1.6266 - precision_25: 0.2837 - recall_25: 0.1515 - auc: 0.7018\n",
      "7) Test metrics - loss: 1.627, prec: 0.284, rec: 0.151, roc_auc: 0.702\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 2.2528 - precision_26: 0.2625 - recall_26: 0.2106 - auc: 0.6447\n",
      "8) Test metrics - loss: 2.253, prec: 0.262, rec: 0.211, roc_auc: 0.645\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.6237 - precision_27: 0.2894 - recall_27: 0.1671 - auc: 0.7041\n",
      "9) Test metrics - loss: 1.624, prec: 0.289, rec: 0.167, roc_auc: 0.704\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 5ms/step - loss: 1.7675 - precision_28: 0.2828 - recall_28: 0.1393 - auc: 0.6381\n",
      "10) Test metrics - loss: 1.768, prec: 0.283, rec: 0.139, roc_auc: 0.638\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.9902 - precision_29: 0.2635 - recall_29: 0.1923 - auc: 0.6858\n",
      "11) Test metrics - loss: 1.990, prec: 0.264, rec: 0.192, roc_auc: 0.686\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.6621 - precision_30: 0.2694 - recall_30: 0.1508 - auc: 0.6852\n",
      "12) Test metrics - loss: 1.662, prec: 0.269, rec: 0.151, roc_auc: 0.685\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.7820 - precision_31: 0.2806 - recall_31: 0.1698 - auc: 0.6780\n",
      "13) Test metrics - loss: 1.782, prec: 0.281, rec: 0.170, roc_auc: 0.678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 2.0878 - precision_32: 0.2745 - recall_32: 0.2133 - auc: 0.6370\n",
      "14) Test metrics - loss: 2.088, prec: 0.274, rec: 0.213, roc_auc: 0.637\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.7163 - precision_33: 0.3287 - recall_33: 0.2405 - auc: 0.7155\n",
      "15) Test metrics - loss: 1.716, prec: 0.329, rec: 0.240, roc_auc: 0.716\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.5565 - precision_34: 0.3060 - recall_34: 0.1726 - auc: 0.7096\n",
      "1) Test metrics - loss: 1.556, prec: 0.306, rec: 0.173, roc_auc: 0.710\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 1.7226 - precision_35: 0.2726 - recall_35: 0.1821 - auc: 0.6866\n",
      "2) Test metrics - loss: 1.723, prec: 0.273, rec: 0.182, roc_auc: 0.687\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.7739 - precision_36: 0.2555 - recall_36: 0.1963 - auc: 0.6806\n",
      "3) Test metrics - loss: 1.774, prec: 0.256, rec: 0.196, roc_auc: 0.681\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.4799 - precision_37: 0.3976 - recall_37: 0.2283 - auc: 0.7444\n",
      "4) Test metrics - loss: 1.480, prec: 0.398, rec: 0.228, roc_auc: 0.744\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.6578 - precision_38: 0.3033 - recall_38: 0.1671 - auc: 0.6865\n",
      "5) Test metrics - loss: 1.658, prec: 0.303, rec: 0.167, roc_auc: 0.687\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 5ms/step - loss: 1.6076 - precision_39: 0.2471 - recall_39: 0.1576 - auc: 0.6882\n",
      "6) Test metrics - loss: 1.608, prec: 0.247, rec: 0.158, roc_auc: 0.688\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 5ms/step - loss: 1.4607 - precision_40: 0.2667 - recall_40: 0.0652 - auc: 0.6969\n",
      "7) Test metrics - loss: 1.461, prec: 0.267, rec: 0.065, roc_auc: 0.697\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.3477 - precision_41: 0.4566 - recall_41: 0.1359 - auc: 0.7372\n",
      "8) Test metrics - loss: 1.348, prec: 0.457, rec: 0.136, roc_auc: 0.737\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 5ms/step - loss: 1.7338 - precision_42: 0.2436 - recall_42: 0.1291 - auc: 0.6726\n",
      "9) Test metrics - loss: 1.734, prec: 0.244, rec: 0.129, roc_auc: 0.673\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.7662 - precision_43: 0.2994 - recall_43: 0.1698 - auc: 0.6758\n",
      "10) Test metrics - loss: 1.766, prec: 0.299, rec: 0.170, roc_auc: 0.676\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.6320 - precision_44: 0.2987 - recall_44: 0.1365 - auc: 0.6949\n",
      "11) Test metrics - loss: 1.632, prec: 0.299, rec: 0.137, roc_auc: 0.695\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 5ms/step - loss: 1.7859 - precision_45: 0.2655 - recall_45: 0.1800 - auc: 0.6631\n",
      "12) Test metrics - loss: 1.786, prec: 0.266, rec: 0.180, roc_auc: 0.663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.4005 - precision_46: 0.3674 - recall_46: 0.2052 - auc: 0.7508\n",
      "13) Test metrics - loss: 1.400, prec: 0.367, rec: 0.205, roc_auc: 0.751\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.5131 - precision_47: 0.3291 - recall_47: 0.1583 - auc: 0.7189\n",
      "14) Test metrics - loss: 1.513, prec: 0.329, rec: 0.158, roc_auc: 0.719\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.9116 - precision_48: 0.2419 - recall_48: 0.2018 - auc: 0.6743\n",
      "15) Test metrics - loss: 1.912, prec: 0.242, rec: 0.202, roc_auc: 0.674\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.6108 - precision_49: 0.2834 - recall_49: 0.1861 - auc: 0.6901\n",
      "1) Test metrics - loss: 1.611, prec: 0.283, rec: 0.186, roc_auc: 0.690\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.6608 - precision_50: 0.2572 - recall_50: 0.1461 - auc: 0.6797\n",
      "2) Test metrics - loss: 1.661, prec: 0.257, rec: 0.146, roc_auc: 0.680\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.6057 - precision_51: 0.2944 - recall_51: 0.1440 - auc: 0.7033\n",
      "3) Test metrics - loss: 1.606, prec: 0.294, rec: 0.144, roc_auc: 0.703\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.4535 - precision_52: 0.3674 - recall_52: 0.1807 - auc: 0.7256\n",
      "4) Test metrics - loss: 1.454, prec: 0.367, rec: 0.181, roc_auc: 0.726\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.3784 - precision_53: 0.3533 - recall_53: 0.0883 - auc: 0.7359\n",
      "5) Test metrics - loss: 1.378, prec: 0.353, rec: 0.088, roc_auc: 0.736\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.5071 - precision_54: 0.3012 - recall_54: 0.1807 - auc: 0.7156\n",
      "6) Test metrics - loss: 1.507, prec: 0.301, rec: 0.181, roc_auc: 0.716\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 5ms/step - loss: 1.3781 - precision_55: 0.3362 - recall_55: 0.0802 - auc: 0.7255\n",
      "7) Test metrics - loss: 1.378, prec: 0.336, rec: 0.080, roc_auc: 0.725\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.5325 - precision_56: 0.2774 - recall_56: 0.1359 - auc: 0.7005\n",
      "8) Test metrics - loss: 1.533, prec: 0.277, rec: 0.136, roc_auc: 0.700\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 5ms/step - loss: 1.4203 - precision_57: 0.3442 - recall_57: 0.1365 - auc: 0.7381\n",
      "9) Test metrics - loss: 1.420, prec: 0.344, rec: 0.137, roc_auc: 0.738\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.6589 - precision_58: 0.2749 - recall_58: 0.2154 - auc: 0.6908\n",
      "10) Test metrics - loss: 1.659, prec: 0.275, rec: 0.215, roc_auc: 0.691\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.4512 - precision_59: 0.3473 - recall_59: 0.1128 - auc: 0.7188\n",
      "11) Test metrics - loss: 1.451, prec: 0.347, rec: 0.113, roc_auc: 0.719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 5ms/step - loss: 1.4244 - precision_60: 0.3506 - recall_60: 0.0829 - auc: 0.7178\n",
      "12) Test metrics - loss: 1.424, prec: 0.351, rec: 0.083, roc_auc: 0.718\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.4003 - precision_61: 0.3438 - recall_61: 0.0740 - auc: 0.7245\n",
      "13) Test metrics - loss: 1.400, prec: 0.344, rec: 0.074, roc_auc: 0.724\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.7019 - precision_62: 0.2738 - recall_62: 0.1467 - auc: 0.6879\n",
      "14) Test metrics - loss: 1.702, prec: 0.274, rec: 0.147, roc_auc: 0.688\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.4589 - precision_63: 0.2899 - recall_63: 0.1135 - auc: 0.7028\n",
      "15) Test metrics - loss: 1.459, prec: 0.290, rec: 0.113, roc_auc: 0.703\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.2982 - precision_64: 0.3803 - recall_64: 0.0550 - auc: 0.7372\n",
      "1) Test metrics - loss: 1.298, prec: 0.380, rec: 0.055, roc_auc: 0.737\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.3135 - precision_65: 0.3955 - recall_65: 0.0836 - auc: 0.7599\n",
      "2) Test metrics - loss: 1.314, prec: 0.395, rec: 0.084, roc_auc: 0.760\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.3155 - precision_66: 0.3562 - recall_66: 0.0353 - auc: 0.7294\n",
      "3) Test metrics - loss: 1.316, prec: 0.356, rec: 0.035, roc_auc: 0.729\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 5ms/step - loss: 1.2737 - precision_67: 0.4293 - recall_67: 0.0577 - auc: 0.7432\n",
      "4) Test metrics - loss: 1.274, prec: 0.429, rec: 0.058, roc_auc: 0.743\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 5ms/step - loss: 1.3044 - precision_68: 0.4389 - recall_68: 0.0659 - auc: 0.7318\n",
      "5) Test metrics - loss: 1.304, prec: 0.439, rec: 0.066, roc_auc: 0.732\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 5ms/step - loss: 1.3487 - precision_69: 0.3607 - recall_69: 0.0747 - auc: 0.7329\n",
      "6) Test metrics - loss: 1.349, prec: 0.361, rec: 0.075, roc_auc: 0.733\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 5ms/step - loss: 1.2774 - precision_70: 0.3902 - recall_70: 0.0326 - auc: 0.7487\n",
      "7) Test metrics - loss: 1.277, prec: 0.390, rec: 0.033, roc_auc: 0.749\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.3319 - precision_71: 0.3792 - recall_71: 0.0693 - auc: 0.7405\n",
      "8) Test metrics - loss: 1.332, prec: 0.379, rec: 0.069, roc_auc: 0.740\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.2863 - precision_72: 0.4048 - recall_72: 0.0462 - auc: 0.7439\n",
      "9) Test metrics - loss: 1.286, prec: 0.405, rec: 0.046, roc_auc: 0.744\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.3157 - precision_73: 0.4060 - recall_73: 0.0367 - auc: 0.7205\n",
      "10) Test metrics - loss: 1.316, prec: 0.406, rec: 0.037, roc_auc: 0.720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.3120 - precision_74: 0.4186 - recall_74: 0.0611 - auc: 0.7364\n",
      "11) Test metrics - loss: 1.312, prec: 0.419, rec: 0.061, roc_auc: 0.736\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.3421 - precision_75: 0.3025 - recall_75: 0.0489 - auc: 0.7151\n",
      "12) Test metrics - loss: 1.342, prec: 0.303, rec: 0.049, roc_auc: 0.715\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.3201 - precision_76: 0.3359 - recall_76: 0.0299 - auc: 0.7309\n",
      "13) Test metrics - loss: 1.320, prec: 0.336, rec: 0.030, roc_auc: 0.731\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 1.2580 - precision_77: 0.3966 - recall_77: 0.0625 - auc: 0.7720\n",
      "14) Test metrics - loss: 1.258, prec: 0.397, rec: 0.062, roc_auc: 0.772\n",
      "1/250.........11/250.........21/250.........31/250.........41/250.........51/250.........61/250.........71/250.........81/250.........91/250.........101/250.........111/250.........121/250.........131/250.........141/250.........151/250.........161/250.........171/250.........181/250.........191/250.........201/250.........211/250.........221/250.........231/250.........241/250.........\n",
      "23/23 [==============================] - 1s 5ms/step - loss: 1.3531 - precision_78: 0.3172 - recall_78: 0.0666 - auc: 0.7146\n",
      "15) Test metrics - loss: 1.353, prec: 0.317, rec: 0.067, roc_auc: 0.715\n",
      "            0.05        0.1        0.2        0.3        0.5\n",
      "count  15.000000  15.000000  15.000000  15.000000  15.000000\n",
      "mean    2.262899   1.814203   1.623311   1.509538   1.310049\n",
      "std     0.402558   0.210267   0.161560   0.111161   0.027850\n",
      "min     1.579441   1.576875   1.347717   1.378079   1.258006\n",
      "25%     2.096715   1.631751   1.496492   1.422370   1.292277\n",
      "50%     2.170841   1.767530   1.632045   1.458932   1.313507\n",
      "75%     2.476835   1.945655   1.749988   1.608286   1.326018\n",
      "max     3.036501   2.252846   1.911589   1.701910   1.353057\n",
      "            0.05        0.1        0.2        0.3        0.5\n",
      "count  15.000000  15.000000  15.000000  15.000000  15.000000\n",
      "mean    0.271670   0.282874   0.303403   0.312998   0.380781\n",
      "std     0.036868   0.022421   0.061943   0.036738   0.039761\n",
      "min     0.214368   0.232633   0.241857   0.257177   0.302521\n",
      "25%     0.257204   0.271946   0.260529   0.280372   0.358410\n",
      "50%     0.266881   0.282759   0.298663   0.301246   0.390244\n",
      "75%     0.276828   0.295168   0.317560   0.345729   0.405388\n",
      "max     0.378313   0.328691   0.456621   0.367403   0.438914\n",
      "            0.05        0.1        0.2        0.3        0.5\n",
      "count  15.000000  15.000000  15.000000  15.000000  15.000000\n",
      "mean    0.214764   0.188361   0.165716   0.134918   0.055072\n",
      "std     0.026649   0.029235   0.039232   0.043236   0.016328\n",
      "min     0.125679   0.139266   0.065217   0.074049   0.029891\n",
      "25%     0.213995   0.166780   0.147079   0.100543   0.041440\n",
      "50%     0.224185   0.195652   0.169837   0.136549   0.057745\n",
      "75%     0.225204   0.211277   0.189198   0.163723   0.066236\n",
      "max     0.244565   0.240489   0.228261   0.215353   0.083560\n",
      "            0.05        0.1        0.2        0.3        0.5\n",
      "count  15.000000  15.000000  15.000000  15.000000  15.000000\n",
      "mean    0.660952   0.684530   0.698694   0.710463   0.737136\n",
      "std     0.036644   0.026711   0.027570   0.018287   0.015541\n",
      "min     0.604182   0.637029   0.663056   0.679662   0.714564\n",
      "25%     0.632400   0.676541   0.678184   0.695640   0.730173\n",
      "50%     0.661649   0.685829   0.688168   0.715625   0.736373\n",
      "75%     0.682829   0.707333   0.714265   0.724993   0.743581\n",
      "max     0.734030   0.715523   0.750795   0.738118   0.772026\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'boxplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18652\\2413365601.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# save a box plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msharex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboxplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboxplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mrecalls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboxplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36mboxplot_frame\u001b[1;34m(self, column, by, ax, fontsize, rot, grid, figsize, layout, return_type, backend, **kwargs)\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[0mlayout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m         \u001b[0mreturn_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m     )\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\boxplot.py\u001b[0m in \u001b[0;36mboxplot_frame\u001b[1;34m(self, column, by, ax, fontsize, rot, grid, figsize, layout, return_type, **kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[0mlayout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[0mreturn_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m     )\n\u001b[0;32m    407\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_if_interactive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\boxplot.py\u001b[0m in \u001b[0;36mboxplot\u001b[1;34m(data, column, by, ax, fontsize, rot, grid, figsize, layout, return_type, **kwds)\u001b[0m\n\u001b[0;32m    371\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 373\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplot_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    374\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\boxplot.py\u001b[0m in \u001b[0;36mplot_group\u001b[1;34m(keys, values, ax)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpprint_thing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremove_na_arraylike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m         \u001b[0mbp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboxplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfontsize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtick_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"both\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabelsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'boxplot'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dropouts = [.05, .1, .2, .3, .5]\n",
    "repeats = 15\n",
    "losses, precisions, recalls, aucs = pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "for d in dropouts:\n",
    "    losses[str(d)], precisions[str(d)], recalls[str(d)], aucs[str(d)] = experiment(repeats, train, test, d)\n",
    "print(losses.describe())\n",
    "print(precisions.describe())\n",
    "print(recalls.describe())\n",
    "print(aucs.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b92f4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(2, 2, sharex=True)\n",
    "losses.boxplot(ax=ax[0][0])\n",
    "precisions.boxplot(ax=ax[0][1])\n",
    "recalls.boxplot(ax=ax[1][0])\n",
    "aucs.boxplot(ax=ax[1][1])\n",
    "ax[0][0].set_title('losses')\n",
    "ax[0][1].set_title('precision')\n",
    "ax[1][0].set_title('recall')\n",
    "ax[1][1].set_title('AUC')\n",
    "plt.savefig('boxplot_dropouts.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
